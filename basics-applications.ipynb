{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyOd+ZiQhOHD+Rd8WaMQsaGN"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip install --upgrade pip jupyter ipywidgets\n",
    "!pip install matplotlib numpy pandas seaborn prophet scikit-learn"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from prophet import Prophet\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Automating Data Cleaning"
   ],
   "metadata": {
    "id": "grSyiB49EllQ"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KwF3myfpDRMa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737970826458,
     "user_tz": -60,
     "elapsed": 4203,
     "user": {
      "displayName": "Matteo Rizzo",
      "userId": "11989314678730977352"
     }
    },
    "outputId": "aa641c09-8d8e-4259-d8ae-76081661819d"
   },
   "source": [
    "# Sample dataset with missing values, outliers, and categorical data\n",
    "data = {\n",
    "    'Employee': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Sales': [1000, 2000, np.nan, 50000],  # Outlier in David's sales\n",
    "    'Experience (Years)': [3, 5, 2, np.nan],\n",
    "    'Department': ['Sales', 'HR', 'IT', 'Sales'],\n",
    "    'Bonus': [500, 700, 300, 10000]  # Outlier in Bonus\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Visualize Original Data\n",
    "print(\"\\n--- Original Dataset ---\")\n",
    "print(df)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Employee', y='Sales', data=df)\n",
    "plt.title(\"Original Sales Data\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Employee', y='Experience (Years)', data=df)\n",
    "plt.title(\"Original Experience Data\")\n",
    "plt.ylabel(\"Experience (Years)\")\n",
    "plt.show()\n",
    "\n",
    "# Observations: Missing values and potential outliers are visible.\n",
    "\n",
    "# Step 2: Handle Missing Values\n",
    "print(\"\\n--- Handling Missing Values ---\")\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df['Experience (Years)'] = imputer.fit_transform(df[['Experience (Years)']])\n",
    "df['Sales'] = imputer.fit_transform(df[['Sales']])\n",
    "print(\"Dataset After Imputation:\")\n",
    "print(df)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap=\"viridis\")\n",
    "plt.title(\"Missing Values After Imputation\")\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Handle Outliers\n",
    "print(\"\\n--- Handling Outliers ---\")\n",
    "for column in ['Sales', 'Bonus']:\n",
    "    q95 = df[column].quantile(0.95)\n",
    "    df[column] = np.where(df[column] > q95, q95, df[column])\n",
    "    df[f'{column} Capped'] = np.where(df[column] == q95, \"Yes\", \"No\")\n",
    "\n",
    "print(\"Dataset After Outlier Capping:\")\n",
    "print(df)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df[['Sales', 'Bonus']])\n",
    "plt.title(\"Boxplot After Outlier Handling\")\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Encode Categorical Data\n",
    "print(\"\\n--- Encoding Categorical Data ---\")\n",
    "label_encoder = LabelEncoder()\n",
    "df['Department Encoded'] = label_encoder.fit_transform(df['Department'])\n",
    "print(\"Encoded Departments:\")\n",
    "print(df[['Department', 'Department Encoded']])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Department', y='Department Encoded', data=df)\n",
    "plt.title(\"Encoded Department Data\")\n",
    "plt.show()\n",
    "\n",
    "# Step 5: Standardize Numerical Features\n",
    "print(\"\\n--- Standardizing Numerical Features ---\")\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['Sales', 'Experience (Years)', 'Bonus']\n",
    "df_standardized = df.copy()\n",
    "df_standardized[numerical_features] = scaler.fit_transform(df_standardized[numerical_features])\n",
    "print(\"Standardized Numerical Features:\")\n",
    "print(df_standardized[numerical_features])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_standardized[numerical_features])\n",
    "plt.title(\"Boxplot of Standardized Features\")\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Normalize Numerical Features\n",
    "print(\"\\n--- Normalizing Numerical Features ---\")\n",
    "min_max_scaler = MinMaxScaler()\n",
    "df_normalized = df.copy()\n",
    "df_normalized[numerical_features] = min_max_scaler.fit_transform(df_normalized[numerical_features])\n",
    "print(\"Normalized Numerical Features:\")\n",
    "print(df_normalized[numerical_features])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_normalized[numerical_features])\n",
    "plt.title(\"Boxplot of Normalized Features\")\n",
    "plt.show()\n",
    "\n",
    "# Step 7: Correlation Analysis for Insights\n",
    "print(\"\\n--- Correlation Analysis ---\")\n",
    "numeric_columns = df_standardized.select_dtypes(include=[np.number])\n",
    "correlation_matrix = numeric_columns.corr()\n",
    "print(\"Correlation Matrix (Standardized Data):\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap (Standardized Data)\")\n",
    "plt.show()\n",
    "\n",
    "# Final Cleaned Dataset\n",
    "print(\"\\n--- Final Cleaned Dataset ---\")\n",
    "print(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Employee Productivity Analysis"
   ],
   "metadata": {
    "id": "83m5q8DQEsJ2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Expanded Example Dataset\n",
    "data = {\n",
    "    'Employee': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank', 'Grace', 'Hank', 'Ivy', 'Jack', 'Karen', 'Leo'],\n",
    "    'Sales': [12000, 15000, 10000, 17000, 14000, 9000, 20000, 11000, 18000, 16000, 13000, 8000],\n",
    "    'Hours Worked': [160, 170, 150, 180, 165, 145, 200, 155, 190, 175, 160, 140],\n",
    "    'Customer Satisfaction': [4.2, 4.5, 3.8, 4.8, 4.3, 3.5, 4.9, 3.9, 4.7, 4.6, 4.1, 3.2]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"\\n--- Initial Dataset ---\")\n",
    "print(df)\n",
    "\n",
    "# Step 1: Visualize Original Data\n",
    "print(\"\\n--- Visualizing Original Data Distribution ---\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='Sales', y='Hours Worked', s=100)\n",
    "plt.title(\"Original Data Distribution\")\n",
    "plt.xlabel(\"Sales\")\n",
    "plt.ylabel(\"Hours Worked\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Step 2: Normalize Data for Clustering\n",
    "print(\"\\n--- Normalizing Data for Clustering ---\")\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(df[['Sales', 'Hours Worked', 'Customer Satisfaction']])\n",
    "print(\"Normalized Features (first 5 rows):\")\n",
    "print(pd.DataFrame(features, columns=['Sales', 'Hours Worked', 'Customer Satisfaction']).head())\n",
    "\n",
    "# Step 3: Apply KMeans Clustering\n",
    "print(\"\\n--- Applying KMeans Clustering ---\")\n",
    "n_clusters = 3\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(features)\n",
    "print(f\"Cluster Assignments:\\n{df[['Employee', 'Cluster']]}\")\n",
    "\n",
    "# Calculate silhouette score\n",
    "sil_score = silhouette_score(features, kmeans.labels_)\n",
    "print(f\"Silhouette Score for {n_clusters} clusters: {sil_score:.2f}\")\n",
    "\n",
    "# Add cluster centroids for visualization\n",
    "centroids = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "print(\"\\nCluster Centroids (Original Scale):\")\n",
    "print(pd.DataFrame(centroids, columns=['Sales', 'Hours Worked', 'Customer Satisfaction']))\n",
    "\n",
    "# Step 4: Visualize Clusters with Centroids\n",
    "print(\"\\n--- Visualizing Clusters with Centroids ---\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='Sales', y='Hours Worked', hue='Cluster', palette='viridis', s=100)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='X', s=200, label='Centroids')\n",
    "plt.title(\"Employee Clusters with Centroids\")\n",
    "plt.xlabel(\"Sales\")\n",
    "plt.ylabel(\"Hours Worked\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Step 5: Cluster Analysis - Boxplots\n",
    "print(\"\\n--- Analyzing Clusters with Boxplots ---\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x='Cluster', y='Sales', palette='viridis')\n",
    "plt.title(\"Sales Distribution by Cluster\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x='Cluster', y='Hours Worked', palette='viridis')\n",
    "plt.title(\"Hours Worked Distribution by Cluster\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Hours Worked\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x='Cluster', y='Customer Satisfaction', palette='viridis')\n",
    "plt.title(\"Customer Satisfaction Distribution by Cluster\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Customer Satisfaction\")\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Add Cluster Summary (Exclude Non-Numeric Columns)\n",
    "print(\"\\n--- Adding Cluster Summary ---\")\n",
    "summary = df.drop(columns=['Employee']).groupby('Cluster').mean().reset_index()\n",
    "print(summary)\n",
    "\n",
    "# Step 7: Pairplot for Cluster Analysis\n",
    "print(\"\\n--- Creating Pairplot for Clusters ---\")\n",
    "sns.pairplot(df, vars=['Sales', 'Hours Worked', 'Customer Satisfaction'], hue='Cluster', palette='viridis', corner=True,\n",
    "             diag_kind='kde')\n",
    "plt.suptitle(\"Pairplot of Clusters\", y=1.02)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QJu5qbgBEakz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737970698372,
     "user_tz": -60,
     "elapsed": 6418,
     "user": {
      "displayName": "Matteo Rizzo",
      "userId": "11989314678730977352"
     }
    },
    "outputId": "b8035472-bba4-4520-8be0-9289b1619b49"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Forecasting Sales or Demand"
   ],
   "metadata": {
    "id": "Xtuu6cSEEwJr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Generate a more realistic dataset with seasonality, trend, and random noise\n",
    "np.random.seed(42)  # For reproducibility\n",
    "months = pd.date_range(start='2023-01-01', periods=12, freq='M')\n",
    "trend = np.linspace(2000, 4500, 12)  # Linear growth trend\n",
    "seasonality = 300 * np.sin(2 * np.pi * (months.month - 1) / 12)  # Yearly seasonality\n",
    "noise = np.random.normal(0, 200, 12)  # Random noise\n",
    "\n",
    "# Combine components to create 'y' (sales)\n",
    "sales = trend + seasonality + noise\n",
    "\n",
    "# Create the DataFrame\n",
    "data = {\n",
    "    'ds': months,\n",
    "    'y': sales\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"\\n--- Dataset ---\")\n",
    "print(df)\n",
    "\n",
    "# Initialize Prophet model\n",
    "model = Prophet(yearly_seasonality=True, weekly_seasonality=False)\n",
    "model.fit(df)\n",
    "\n",
    "# Make future predictions\n",
    "future = model.make_future_dataframe(periods=6, freq='M')\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Add forecasted period annotation\n",
    "forecast_period = future[future['ds'] > df['ds'].max()]\n",
    "print(\"\\n--- Forecast Period ---\")\n",
    "print(forecast_period)\n",
    "\n",
    "print(\"\\n--- Forecast Summary ---\")\n",
    "print(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(6))\n",
    "\n",
    "# Plot the forecast with better annotations\n",
    "fig1 = model.plot(forecast)\n",
    "plt.title(\"Sales Forecast with Future Predictions\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Highlight forecasted periods\n",
    "plt.axvspan(df['ds'].max(), future['ds'].max(), color='orange', alpha=0.2, label=\"Forecasted Period\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot forecast components\n",
    "fig2 = model.plot_components(forecast)\n",
    "plt.suptitle(\"Forecast Components\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Extended visualizations\n",
    "print(\"\\n--- Extended Visualizations ---\")\n",
    "\n",
    "# Visualize actual vs predicted sales\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['ds'], df['y'], label='Actual Sales', marker='o')\n",
    "plt.plot(forecast['ds'], forecast['yhat'], label='Predicted Sales', linestyle='--', color='orange')\n",
    "plt.fill_between(forecast['ds'], forecast['yhat_lower'], forecast['yhat_upper'], color='orange', alpha=0.2,\n",
    "                 label='Uncertainty Interval')\n",
    "plt.axvline(df['ds'].max(), color='red', linestyle='--', label='Forecast Start')\n",
    "plt.title(\"Actual vs Predicted Sales\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Highlight seasonality trends (use 'yearly' if it exists in the forecast)\n",
    "if 'yearly' in forecast.columns:\n",
    "    print(\"\\n--- Highlighting Yearly Seasonality Trend ---\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(forecast['ds'], forecast['yearly'], label='Yearly Seasonality', color='green')\n",
    "    plt.title(\"Yearly Seasonality Trend\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Yearly Seasonality Impact\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nYearly seasonality is not available in the forecast.\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "T4JGDcsWEcW1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737971806051,
     "user_tz": -60,
     "elapsed": 2876,
     "user": {
      "displayName": "Matteo Rizzo",
      "userId": "11989314678730977352"
     }
    },
    "outputId": "1aae5b48-5f4c-4ddb-f405-0727e907df72"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Real-Time Expense Monitoring"
   ],
   "metadata": {
    "id": "7jd-oM0lE1u7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Example dataset\n",
    "data = {\n",
    "    'Description': ['Coffee', 'Office Supplies', 'Taxi', 'Lunch', 'Notebook', 'Dinner', 'Train Ticket', 'Pens', 'Uber',\n",
    "                    'Sandwich'],\n",
    "    'Amount': [4.5, 25.0, 30.0, 12.0, 15.0, 20.0, 50.0, 5.0, 35.0, 8.0],\n",
    "    'Category': ['Food', 'Office', 'Transport', 'Food', 'Office', 'Food', 'Transport', 'Office', 'Transport', 'Food']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the dataset\n",
    "print(\"Dataset:\")\n",
    "print(df)\n",
    "\n",
    "# Visualize the dataset\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='Category', palette='viridis')\n",
    "plt.title('Category Distribution')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize amount distribution per category\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x='Category', y='Amount', palette='coolwarm')\n",
    "plt.title('Amount Distribution by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Amount')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Transform data for the classifier\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['Description'])\n",
    "y = df['Category']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf = RandomForestClassifier(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d',\n",
    "            xticklabels=clf.classes_, yticklabels=clf.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print feature importance\n",
    "feature_importances = clf.feature_importances_\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nTop Features by Importance:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=importance_df.head(10), x='Importance', y='Feature', palette='magma')\n",
    "plt.title('Top 10 Features by Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Predict new expenses\n",
    "new_data = ['Uber', 'Printer Ink', 'Pizza', 'Train', 'Laptop']\n",
    "X_new = vectorizer.transform(new_data)\n",
    "predictions = clf.predict(X_new)\n",
    "\n",
    "# Print predictions\n",
    "prediction_df = pd.DataFrame({'Expense': new_data, 'Predicted Category': predictions})\n",
    "print(\"\\nPredictions:\")\n",
    "print(prediction_df)\n",
    "\n",
    "# Visualize predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=prediction_df, x='Expense', y=range(len(predictions)), hue='Predicted Category', dodge=False,\n",
    "            palette='Set2')\n",
    "plt.title('Predicted Categories for New Expenses')\n",
    "plt.xlabel('Expense')\n",
    "plt.ylabel('Index')\n",
    "plt.legend(title='Category')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YXjyuD0REi9U",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737972099571,
     "user_tz": -60,
     "elapsed": 1936,
     "user": {
      "displayName": "Matteo Rizzo",
      "userId": "11989314678730977352"
     }
    },
    "outputId": "aac87be6-2ec5-46b9-cf8c-905850f603c6"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Employee Attrition Prediction"
   ],
   "metadata": {
    "id": "tyloZ_ZTFUD7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Sample dataset\n",
    "data = {\n",
    "    'JobSatisfaction': [3, 2, 4, 1, 3, 2, 5, 4, 3, 1],\n",
    "    'YearsAtCompany': [5, 1, 7, 2, 3, 1, 8, 6, 4, 2],\n",
    "    'PerformanceRating': [4, 3, 5, 2, 4, 3, 5, 4, 4, 2],\n",
    "    'MonthlyIncome': [5000, 2000, 8000, 2500, 4500, 2200, 8500, 7000, 4000, 2100],\n",
    "    'Left': [0, 1, 0, 1, 0, 1, 0, 0, 0, 1]  # 1 = Left the company, 0 = Stayed\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print dataset info\n",
    "print(\"Dataset Summary:\")\n",
    "print(df.describe())\n",
    "print(\"\\nDataset Head:\")\n",
    "print(df.head())\n",
    "\n",
    "# Visualize data distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['MonthlyIncome'], kde=True, color='blue', bins=10)\n",
    "plt.title('Monthly Income Distribution')\n",
    "plt.xlabel('Monthly Income')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x='Left', y='MonthlyIncome', palette='Set2')\n",
    "plt.title('Monthly Income by Attrition Status')\n",
    "plt.xlabel('Attrition Status (Left: 1, Stayed: 0)')\n",
    "plt.ylabel('Monthly Income')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Features and target\n",
    "X = df[['JobSatisfaction', 'YearsAtCompany', 'PerformanceRating', 'MonthlyIncome']]\n",
    "y = df['Left']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Print model evaluation metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n",
    "\n",
    "# Feature importance using permutation importance\n",
    "perm_importance = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "perm_importance_df = pd.DataFrame({\n",
    "    'Feature': X_test.columns,\n",
    "    'Importance': perm_importance.importances_mean\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nPermutation Feature Importance:\")\n",
    "print(perm_importance_df)\n",
    "\n",
    "# Bar plot for feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=perm_importance_df, x='Importance', y='Feature', palette='viridis')\n",
    "plt.title('Permutation Feature Importance')\n",
    "plt.xlabel('Mean Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize feature importance for a single prediction (simple example)\n",
    "sample_idx = 0\n",
    "sample_features = X_test.iloc[sample_idx]\n",
    "sample_prediction = model.predict_proba([sample_features])[0]\n",
    "\n",
    "print(f\"\\nPrediction probabilities for sample {sample_idx}:\")\n",
    "for class_idx, prob in enumerate(sample_prediction):\n",
    "    print(f\"Class {class_idx}: {prob:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(X_test.columns, sample_features, color='teal')\n",
    "plt.title(f'Feature Values for Sample {sample_idx}')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CSLJcE1FFRVt",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737973250714,
     "user_tz": -60,
     "elapsed": 3847,
     "user": {
      "displayName": "Matteo Rizzo",
      "userId": "11989314678730977352"
     }
    },
    "outputId": "3d89575f-362a-4a10-e6c3-9dea9c4b52f3"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
